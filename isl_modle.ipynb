{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15718f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\akshg\\AppData\\Local\\Temp\\ipykernel_5264\\2767822615.py\", line 31, in <module>\n",
      "    hf_train_dataset = convert_to_hf_dataset(train_dataset)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshg\\AppData\\Local\\Temp\\ipykernel_5264\\2767822615.py\", line 28, in convert_to_hf_dataset\n",
      "    images, labels = zip(*[(image, label) for image, label in img_dataset])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshg\\AppData\\Local\\Temp\\ipykernel_5264\\2767822615.py\", line 28, in <listcomp>\n",
      "    images, labels = zip(*[(image, label) for image, label in img_dataset])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshg\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\datasets\\folder.py\", line 247, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshg\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\transforms.py\", line 95, in __call__\n",
      "    img = t(img)\n",
      "          ^^^^^^\n",
      "  File \"C:\\Users\\akshg\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\transforms.py\", line 137, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akshg\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\functional.py\", line 176, in to_tensor\n",
      "    return img.to(dtype=default_float_dtype).div(255)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 602112 bytes.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\executing\\executing.py\", line 317, in executing\n",
      "    args = executing_cache[key]\n",
      "           ~~~~~~~~~~~~~~~^^^^^\n",
      "KeyError: (<code object run_code at 0x00000262016E4690, file \"D:\\anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490>, 2619954054800, 202)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1160, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\stack_data\\core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\stack_data\\core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\stack_data\\core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\executing\\executing.py\", line 369, in executing\n",
      "    args = find(source=cls.for_frame(frame), retry_cache=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\executing\\executing.py\", line 252, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\executing\\executing.py\", line 270, in for_filename\n",
      "    result = source_cache[filename] = cls._for_filename_and_lines(filename, lines)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\executing\\executing.py\", line 281, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\stack_data\\core.py\", line 79, in __init__\n",
      "    super(Source, self).__init__(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\executing\\executing.py\", line 228, in __init__\n",
      "    self.tree = ast.parse(ast_text, filename=filename)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\anaconda\\Lib\\ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import TrainerCallback\n",
    "import gc\n",
    "\n",
    "# Set up the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define image transformations (resize, normalize, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resizing images to match ViT input size\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize based on ImageNet\n",
    "])\n",
    "\n",
    "# Load dataset from folders using torchvision's ImageFolder\n",
    "train_dataset = ImageFolder(root='C:\\\\Users\\\\akshg\\\\Downloads\\\\traning', transform=transform)\n",
    "test_dataset = ImageFolder(root='C:\\\\Users\\\\akshg\\\\Downloads\\\\test', transform=transform)\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "def convert_to_hf_dataset(img_dataset):\n",
    "    # Get images and labels from ImageFolder dataset\n",
    "    images, labels = zip(*[(image, label) for image, label in img_dataset])\n",
    "    return Dataset.from_dict({\"image\": list(images), \"label\": list(labels)})\n",
    "\n",
    "hf_train_dataset = convert_to_hf_dataset(train_dataset)\n",
    "hf_test_dataset = convert_to_hf_dataset(test_dataset)\n",
    "\n",
    "# Initialize the feature extractor and model\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', num_labels=len(train_dataset.classes))\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Preprocess the images (extract features)\n",
    "def preprocess_images(examples):\n",
    "    images = [image.numpy() for image in examples['image']]\n",
    "    # Extract features using the feature extractor\n",
    "    features = feature_extractor(images, return_tensors='pt')\n",
    "    # Move tensors to the same device as the model\n",
    "    return {k: v.to(device) for k, v in features.items()}\n",
    "\n",
    "\n",
    "# Apply preprocessing to datasets\n",
    "hf_train_dataset = hf_train_dataset.map(preprocess_images, batched=True)\n",
    "hf_test_dataset = hf_test_dataset.map(preprocess_images, batched=True)\n",
    "\n",
    "\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # Enable mixed precision training if desired\n",
    "    fp16=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "\n",
    "class MemoryManagementCallback(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        # Clear memory after every epoch\n",
    "        print(f\"Epoch {state.epoch} finished. Clearing memory...\")\n",
    "        torch.cuda.empty_cache()  # Clear GPU cache\n",
    "        gc.collect()  # Clear unused objects from memory\n",
    "\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train_dataset,\n",
    "    eval_dataset=hf_test_dataset,\n",
    "    callbacks=[MemoryManagementCallback()]  # Add the callback here\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b89645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cpu\n",
      "0.19.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b44953f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ac123",
   "metadata": {},
   "outputs": [],
   "source": [
    "D:\\anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
    "  torch.utils._pytree._register_pytree_node("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
